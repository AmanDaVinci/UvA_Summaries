%\section{Monte-Carlo Tree Search and Alpha Go}
%\label{sec:MCTS_Alpha_Go}
%\textit{This section reviews the lecture slides 12.}
%\begin{itemize}
%	\item In Section~\ref{sec:value_based_approximation}, we have seen that to learn a value function for problems with very large state space, we can approximate our $q$-function by e.g. a neural network. However, these approximations will always contain a certain amount of noise/inaccuracy.
%	\item An alternative approach is to learn $q(s,a)$ \underline{online}. The simplest approach for this is to perform rollouts 
%\end{itemize}
